<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>JCES - USabana</title>
        <link rel="stylesheet" href="../jcunisabana.github.io/css/bootstrap.min.css">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css">


		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css" >
						<link rel="stylesheet" href="css/estilo.css">

    <!-- para íconos chéveres-->

<script src="https://use.fontawesome.com/503e7c40b4.js"></script>
        
    <!--    google analytics-->
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74338484-2', 'auto');
  ga('send', 'pageview');

</script>    
        
	</head>
<body>
<div class="reveal">
<div class="slides">





<section  data-background-color="white" data-background-image ="img/ggm.png" data-background-size = "contain" data-background-position="right">

<div class="container">
<div class="row">

<div class="col-md-7"> 
    <h1><br></h1>

<h2 style="text-align:left; background-color:white; color:#022461; ">Ética de la inteligencia artificial</h2>
    
    <div class="col-md-6"> 
        <p style="text-align:left; background-color:white; color:#022461;"> <font size="5">Juan Camilo Espejo-Serna</font> <br> <font size="4">Universidad de la Sabana<br>juan.espejo1@unisabana.edu.co</font>
        <br><br></p></div>
<!--    <div style="text-align:left; background-color:white; color:#022461;"><a style="color:#022461; text-decoration: underline;" href="../jcunisabana.github.io/">Juan Camilo Espejo Serna</a>-->

<!--
<font size="5"><span style="text-align:left; background-color:white; color:#022461; font-family:'Lucida Console', monospace"><smal>juan.espejo1@unisabana.edu.co</smal></span>
</font> 
-->
    </div>
      
</div>
   

</div>	

</section>
    

            <section>
                <h2>Objetivos</h2>
                <ol>
                    <li>Entender qué es la IA real para distinguirla de los casos de ciencia ficción.</li>
                    <li>Reconocer algunos de los retos éticos específicos de la IA real a través de casos concretos.</li>

                </ol>
            </section>
    

    
    
<section>
<h2>Plan</h2>
    <ol>
    <li class="fragment">Problemas éticos y la dificultad para identificarlos</li>
    <li class="fragment">Concepciones aditivas y transformativas de la ética</li>
    <li class="fragment">Problemas éticos y la razón de la dificultad para encontrarlos</li>

    </ol>
    </section>    

<section  data-background-color="white" data-background-image ="img/ggm.png" data-background-size = "contain" data-background-position="right">

<div class="container">
<div class="row">

<div class="col-md-7"> 
 
<h3 style="text-align:left; background-color:white; color:#022461; ">Problemas éticos y la dificultad para identificarlos</h3>
    </div>
      
</div>
</div>	
</section>   
    
    
    <section>
    
        
    La tecnología evidencia la actitud ética de sus creadores.  En esta ocasión hablaremos de los problemas éticos que hay con la tecnología sesgada.    
        
        <p class="fragment">Consideremos algunos ejemplos.</p>
        
    </section>
    
    
    
    <section>
        <div class="">
    Si quien diseña un edificio no tiene en mente a personas con diferentes capacidades puede terminar con un edificio difícil de ser usado por una persona en silla de ruedas o con que camina con bastón.
        
        <p class="fragment">Aquí hay un sesgo.</p></div>
        
    </section>
    
     <section>
         
        <div class="">Si quien diseña una app no tiene en mente a personas con diferentes capacidades puede diseñar una app difícil de ser usada por una persona invidente.         
        <p class="fragment">Aquí hay un sesgo.</p>
        </div> 
<div></div>
    </section>
    
    <section>
    ¿y en el caso de la IA?
    <p class="fragment">Como dije la sesión pasada, es necesario ver los casos reales de IA. Por eso vamos a hablar del caso de Machine learning, el nombre de la tecnología más ampliamente usada en la actualidad.</p>
    </section>
<section>        <div class="">

   Tecnologías como un algoritmo generado por “machine learning”: un algoritmo con la función de “despixelar” imágenes de caras humanas, por ejemplo, puede ofrecer resultados con una constitución racial y de edad que "borra" los rasgos menos comunes en sus bases de entrenamiento y que el algoritmo de entrenamiento no seleccionó como relevantes.  (¿Han visto Coded Bias en Netflix?)
    
    <p class="fragment">Aquí hay un sesgo contra las personas con esos rasgos.</p>
    </div>
    
    
    </section>    
    
    
<section>
    
     <em>Machine learning</em>: una forma particular de IA que agrupa una multiplicidad de métodos que en esencia dependen de un aprendizaje a partir de una base de datos.
    </section>    
    
    
    
    
    <section>
    <div class="">
    En el caso del ML, el algoritmo no ha sido específicamente diseñado por humanos; ese comportamiento de eliminar rasgos no viene directamente determinado por la intención de un programador.
        
    <p class="fragment">Por eso es difícil encontrar el lugar en donde se incorpora el sesgo, ni asignar la responsabilidad y procurar una forma de eliminarlo. </p>    </div>    
        
    
    </section>
    
    <section>"<em>Garbage in; garbage out</em>" suele ser la explicación dada por los ingenieros trabajando en un programa que toma decisiones sesgadas. La idea es que se puede mejorar los datos de entrenamiento y solucionar así el problema. </section>
    
    
    <section>
        Pero su funcionamiento es una caja negra de la cual sólo se tiene información limitada y no es fácil determinar dónde está el problema para solucionarlo. <span class="fragment">Entonces se hace lo que se puede </span><span class="fragment">antes</span><span class="fragment">, durante</span> <span class="fragment">y después del procesamiento </span><span class="fragment">y aún así, como veremos, hay problemas.</span>
    
    </section>
    
    <section>¿caja negra?</section>
    
    <section>Primero comparémoslo con lo que podemos llamar la IA del siglo XX</section>
        <section>Intrucciones sencillas, formuladas explícitamente, que juntas y en masa terminan ofreciendo un comportamiento sorprendentemente complejo.</section>

    <section>
<a href="https://playgameoflife.com/">Ejemplo: The game of life de Conway</a>
</section>

    
        <section>Intrucciones sencillas, formuladas explícitamente, que juntas y en masa terminan ofreciendo un comportamiento sorprendentemente complejo.
    
    <p class="fragment">En el caso de ML no hay una formulación explícita de las reglas para la conducta del programa. Hay una formulación explícita de un algoritmo de aprendizaje y de una base de datos de entrenamiento, pero no hay un momento en que se formulen las reglas por medio  de las cuales el programa ha de comportarse. </p>
    </section>

    
    <section>Veamos con un poco más detalle para ver cómo funciona el ML y dónde podríamos encontrar problemas.</section>    
    
    <section><div class=""> La idea general del ML es que a partir de una base de datos y un mecanismo de aprendizaje es posible generar un programa que realice a una tarea específica. Así, el tipo de aprendizaje que se utilice cambiará el resultado. Aquí una explicación rápida de la idea del aprendizaje en ML.</div> </section>
    
<section>
    Si bien hay varios tipos de aprendizaje, voy a tomar el caso del aprendizaje supervisado como un caso donde podemos ver dónde puede haber claramente tanto sesgos humanos como sesgos que no vienen de lo que piensan los diseñadores del programa. <span class="fragment">En los casos de aprendizaje sin supervisión y el caso de aprendizaje por refuerzo puede que sea incluso más difícil determinar el tipo de sesgo y su origen;</span> <span class="fragment"> tanto peor para la posibilidad usual de seleccionar y reparar los sesgos. </span> <span class="fragment">Todo tipo de programa estará atado al menos a alguna de las maneras en que hay sesgos en el aprendizaje supervisado, entonces al estudiar este caso podemos ver los problemas generales.
    </span>
    </section>    
    
    <section>Así, empecemos con el caso del aprendizaje supervisado. Un programa se produce a partir de una base de datos que ha sido previamente categorizada gracias a la cual se aprende la relación entre los datos ofrecidos y esas categorías señaladas. </section>
    
    <section  data-background-image ="img/cats.jpg" data-background-size = "contain" >
    
    <p class="fragment highlightred">Podemos tener un programa para identificar gatos caseros que parte de una base de datos de imágenes de animales que han sido categorizadas entre gatos y no-gatos de manera que luego permite, para una imagen de una mascota que no estaba dentro de los datos de entrenamiento, determinar si se trata de un gato.</p>
    </section>
    
        <section  data-background-image ="img/cats.jpg" data-background-size = "contain" > 
            
            <p class=" highlightred">La categorización puede ser tan fina como sea programada: se puede señalar que los gatos tienen también ojos grandes, tamaño y forma general y luego esta misma categorización será empelada para determinar en los casos por fuera de la base de datos de entrenamiento si se trata de un gato o no. <span class="fragment">(O, en el caso de modos de aprendizaje sin supervisión, será tan fina como sea realizada por el algoritmo mismo.)</span></p>
    </section>
    
    <section>Es importante apreciar cómo la base de datos seleccionada puede sesgar al programa.</section>
    
        <section  data-background-image ="img/cateye.jpg" data-background-size = "contain" > 
                     <p class=" highlightred doscuadros">
                         Si la base de datos sólo incluía pájaros y gatos, la cantidad de no-gatos con cuatro patas sería radicalmente diferente de lo que esperaríamos de una base de datos de mascotas que sólo tiene gatos y perros. Entonces, la manera de seleccionar gatos tendrá un sesgo en favor de las características que distinguen gatos de pájaros y no necesariamente aquellas que son propiamente felinas. <br> <span class="fragment">Si la base de datos no es representativa de la población, tendremos problemas. </span></p> 
    
    </section>

      <section  data-background-image ="img/cateye.jpg" data-background-size = "contain" > 
                     <p class=" highlightred doscuadros">
                         Si quien categoriza tiene su propio sesgo en favor de la selección de gatos, entonces podríamos esperar que los datos estuviesen sesgados en la medida en que cargan con los sesgos de quien ha realizado la categorización. Incluso si tenemos una base de datos representativa puede que haya un sesgo en la medida en que la manera en que ha sido categorizada dé prioridad a una forma específica de entender qué es un gato. <span class="fragment">Si la base de datos está categorizada de manera sesgadas, tendremos problemas. </span>            </p>
    
    </section>

      <section  data-background-image ="img/cateye.jpg" data-background-size = "contain" > 
          <div class="doscuadros">
          <p class=" highlightred ">    Una forma adicional en que los datos pueden estar sesgados es que la base de datos refleja apropiadamente cómo es la realidad, pero resulta que la realidad misma está sesgada.</p>
          </div>
    </section>
    
    <section>
          <h1 class="fragment ">¿?</h1>
    <p class="fragment">¿Cómo así que la realidad está sesgada?</p>
    </section>
    
    <section>Aquí nuestro ejemplo de los gatos deja de tener mucho sentido pues no parece haber razón para pensar en que hay un sesgo en contra o en favor de los gatos en la realidad. Pero justamente los programas en ML van más allá de estos casos de juguete y es ahí en donde se pueden ver los problemas más importantes. 
    
    <p class="fragment">Entonces veamos un ejemplo real.</p>
    </section>
    
    
    <section>La aplicación Face De-Pixelizer tiene como entrada una imagen de una persona en baja resolución y como salida una imagen de alta calidad. De acuerdo con la descripción inicial del proyecto, se trata de una red neuronal entrenada con una base de datos amplia de fotos de personas en la plataforma Flikr que toma imágenes pixeladas y las despixela. </section>
    
      <section  data-background-image ="img/pulse.png" data-background-size = "contain" > 
</section>
    <section>A pesar de su maravilloso desempeño en algunas áreas, Face De-Pixelizer también puede devolver una imagen en que un adulto promedio, razonablemente bien informado, claramente podría reconocer que no es una versión despixelada de la original. </section>
    
    
    
    
          <section  data-background-image ="img/pulse2.png" data-background-size = "contain" > 
    </section>
    
    <section>La imagen de entrada es de un hombre colombiano viejo y el resultado es un joven caucásico. </section>
    
          <section  data-background-image ="img/pulse2.png" data-background-size = "contain" > 
<p class="highlightred fragment">
            Una razón por la que podemos pensar que hay un sesgo aquí es que la interpretación de los rasgos característicos de una persona que ha ofrecido el algoritmo es que son errores de la imagen, tal y como la pixelación, y los eliminado. </p></section>

    
<section>
    <p class="">    Esto bien puede ser por la manera particular en que se seleccionó la base de datos. 
</p>
    <p class="fragment">   Alternativamente, se podría decir que el problema está que en la categorización usada se adoptó por etiquetas que no dan la posibilidad de categorizar con base en la edad -borrando efectivamente las diferencias de edades y optando por una edad general de la base de datos. </p>
    <p class="fragment">Por último, bien puede ser que en la sociedad de donde se toman los datos, los rasgos caucásicos son más prevalentes o importantes o más privilegiados en las representaciones pictóricas</p>
    <p class="fragment">    Dada la multiplicidad de maneras en que se podría entender, ¿cómo entender el problema? No tenemos una respuesta clara todavía. (Los desarrolladores se salieron por la tangente.)
</p>

    
    </section>    
    
        <section data-background-image ="img/librosvarios.png" data-background-size = "contain" data-background-position="right">
            
        <p class="fragment highlightred">Afortunadamente, la existencia de sesgos de este tipo no es información confidencial. Ya hay personas dentro de la comunidad en IA e incluso por fuera de ella son conscientes de las posibilidades de sesgos y están atentos a la necesidad de solucionarlos. </p>    
    </section>

    
        <section data-background-image ="img/librosvarios.png" data-background-size = "contain" data-background-position="right">
            
        <p class="fragment highlightred">Esto no se debe tomar a la ligera; es ya un mérito que se esté identificando el hecho de que hay un problema pues es fácil dejarse llevar por la “objetividad” de un algoritmo que opera a partir de bases de datos “neutralmente” obtenidas –un algoritmo que está bien en la medida en que logra reflejar una sociedad que está mal.</p>    
    </section>
    
    <section data-background-image ="img/blindaudition.jpg" data-background-size = "contain">
        <p>(Pequeño paréntesis sobre la <br>confusión entre neutralidad y objetividad)</p></section>
    
    
    <section><h1>PERO</h1>
        
        Recibir atención y recibir solución son dos cosas diferentes. ¿Qué tipo de soluciones se han sugerido? </section>
    
    
    <section data-background-image ="img/sol1.png" data-background-size = "contain" data-background-position="right">
    <p class="trescuadros highlightred">Suresh y Guttag (2019) </p>
    </section>
    
    <section data-background-image ="img/survey.png" data-background-size = "contain" data-background-position="right">
    <div class="trescuadros highlightred">Mehrabi et al. (2019)<br>    concluyen que los métodos reseñados buscan, en la mejor de las condiciones, que haya una mismidad de trato para todos pero que eso no evita el tipo de sesgo que ya hemos señalado de acuerdo con el cual el programa está sesgado en la medida en que es un reflejo “bueno” de una sociedad injusta. 
     </div>
    </section>


    
     <section data-background-image ="img/gebru.jpg" data-background-size = "contain" data-background-position="right">
    <div class="doscuadros ">
    <p class="highlightred">Timnit Gebru, por ejemplo, estuvo trabajando en Google, desde adentro, procurando maneras específicas de llevar a la compañía a vivir el que era su lema de “Do no evil”, pero justo fue despedida a raíz de que su investigación. Lo que da la impresión de que Google quiere que se cumpla con la letra del lema sin el trabajo duro que implica implementar su espíritu.
         
         </p><p class=" fragment highlightred">Parte de lo que gente como Gebru apunta es que necesitamos un cambio en el ambiente de estudio y diseño de la IA; no pañitos de agua tibia.</p></div>
    </section>
    
    <section>Hasta aquí el recuento esquemático del problema y de las propuestas de solución.</section>
    <section>
    Quiero proponer, a modo de diagnóstico de la situación y de la respuesta propuesta por investigadoras como Gebru, que la razón por la que las medidas adoptadas no funcionan y se requiere una reforma de raíz es que se necesita repensar la relación con la ética en la IA. El problema, quiero sugerir, yace en una concepción particular del razonamiento ético. 
    
    </section>
    <section  data-background-color="white" data-background-image ="img/ggm.png" data-background-size = "contain" data-background-position="right">

<div class="container">
<div class="row">

<div class="col-md-7"> 
 
<h3 style="text-align:left; background-color:white; color:#022461; ">Concepciones aditivas y transformativas de la ética</h3>
    </div>
      
</div>
</div>	
</section> 
    
<section>¿Qué es el razonamiento ético?</section> 
    
<section  data-background-image ="img/velleman.jpg" data-background-size = "contain" data-background-position="right">
    <p class="doscuadros highlightred">"Supongamos que se le encarga la tarea de diseñar un agente autónomo, dado el diseño para un mero sujeto de motivación. Si lo desea, puede asignarse imaginativamente a la gerencia media divina como líder del proyecto para la sexta tarde de la creación; o puede que prefiera asumir el papel de la selección natural durante los milenios correspondientes. En cualquier caso, se enfrenta a un mundo ya poblado de animales inferiores, que son capaces de una actividad motivada, y su tarea es introducir agentes autónomos.</p>
    </section>    
    
<section  data-background-image ="img/velleman.jpg" data-background-size = "contain" data-background-position="right">
    <p class="doscuadros highlightred">Más bien, agregaría una razón práctica al diseño existente para criaturas motivadas, y lo agregaría en forma de un mecanismo que modifica las fuerzas motivacionales que ya están en funcionamiento. Diseñaría una razón práctica que examinara los motivos de la criatura, bloqueara o inhibira algunos de ellos y reforzara otros.</p>
    </section>    
    
    <section  data-background-image ="img/velleman.jpg" data-background-size = "contain" data-background-position="right">
    <p class="doscuadros highlightred">Una criatura dotada de tal mecanismo reflexionaría sobre las fuerzas dentro de sí que ya eran capaces de producir un comportamiento por sí mismas -como lo hacen en las criaturas no autónomas o en su propio comportamiento no autónomo. Su razonamiento práctico sería un proceso de evaluación de estos resortes de acción y su intervención en sus operaciones, cuya intervención requeriría un resorte de acción racional adicional capaz de modificar o redirigir la fuerza ejercida por los otros resortes. (Velleman 2000, 11-12)"</p>
    </section>    
    
    <section>Velleman nos invita a suponer que estuviésemos encargados de diseñar e implementar un sujeto autónomo. De acuerdo con su historia, la pregunta es cómo pasar de un animal que tiene capacidad de actividad meramente motivada por deseos a un sujeto autónomo que actúa por razones.  Es decir, pasar de un sujeto con comportamiento a un sujeto que actúa por razones</section>
   
    <section>La manera de hacerlo, afirma Velleman, sería tomar en mecanismo existente que ya da resultados pero que no está guiado por consideraciones de la razón práctica y añadir un mecanismo evaluador y seleccionador. El razonamiento ético de este tipo de organismos consistiría en la evaluación de su comportamiento pre-ético y la intervención en ese comportamiento según lo que diga la razón práctica.</section>
    
    
    <section>La imagen de Velleman y la forma en que se ha desarrollado la IA tienen en común que se piensa la ética como algo que regula, organiza, inhibe o refuerza un comportamiento que ya existe.
        
        <p class="doscuadros fragment fade-in-then-semi-out"> La creatura imaginada por Velleman cuenta con la capacidad para la reflexión ética en la medida en que tiene comportamientos resultado de la motivación que adicionalmente son revisados y orientados por la el razonamiento ético.</p>
        <p class="doscuadros fragment">De manera análoga podemos ver a los programas creados por ML como si les faltase incorporar justo un tipo de capacidad adicional en la forma de la reflexión ética: falta en la IA un proceso que regule los resultados que ya se tienen. </p>
        
        </section>
    <section>Justo eso es lo que está mal.</section>
    <section  data-background-color="white"><p style="text-align:left; background-color:white; color:#022461; ">    Quiero sugerir que el avance en ética de la IA está estancado en la medida en que se tiene un modelo como el de Velleman y se busca eliminar los sesgos por medio de un mecanismo adicional que regula el comportamiento ya bien definido del programa. Aquellas propuestas más revolucionarias, y que en mi opinión tienen mayor promesa, tienen en común una interpretación de las maneras de intentar resolver los problemas que implica una reformulación substancial del programa mismo de IA.
</p> </section>
    
    
    <section><h2>Concepción aditiva <br>vs<br> Concepción transformativa</h2> </section>
    
    <section>Para explicar el tipo de relación con la ética de este tipo de concepciones voy a tomar dos ejemplos: primero, voy a hablar de la concepción aristotélica de animal racional  y luego voy a hablar sobre colores. </section>
    
    
    <section  data-background-image ="img/aristo-old.jpg" data-background-size = "contain" data-background-position="right">
        <p class="doscuadros">Los humanos somos animales racionales y la forma particular en que somos racionales no sólo es algo que se adiciona a nuestra condición animal, sino que transforma la manera particular en que somos animales. </p>
    </section>
    
    <section  data-background-image ="img/aristo-old.jpg" data-background-size = "contain" data-background-position="right">
        <p class="doscuadros">    Si la racionalidad fuese una mera adición a nuestra animalidad, entonces nuestro carácter animal sería del mismo tipo que el de otros animales no-racionales: seríamos diferentes de los animales no-racionales en que tenemos algo más pero nuestra animalidad sería la misma.  En cambio, si la racionalidad se considera como una transformación de nuestra animalidad, nuestro carácter animal es de un tipo diferente de la animalidad de los no-racionales. 
 </p>
    </section>
    <section>Por favor le pido al a los aristotélicos y anti-aristotélicos: paciencia. No es mi intención defender una lectura de Aristóteles sino sacar una lección de ésta. </section>
    
        <section  data-background-image ="img/aristo-old.jpg" data-background-size = "contain" data-background-position="right">
            <div class="doscuadros">
                Dos maneras de marcar la diferencia entre nosotros y los demás animales.
            <ol >
            <li>    Somos diferentes de los animales no-racionales en que tenemos algo más que la animalidad.
</li>
            <li>    Somos diferentes de los animales no-racionales en que nuestro carácter animal mismo es diferente, no sólo en que tenemos algo más que la animalidad.
</li>
            </ol></div>
    </section>
    
<section>Ahora el mismo tipo de relación, pero con los colores.</section>
    
    <section  data-background-image ="img/redball.jpg" data-background-size = "contain" data-background-position="right">
       
        
        <div class="doscuadros highlightred">       
            Dos maneras de entender en qué consiste tener un color.
            <ol class=" ">
            <li class="" >    Una bola de color rojo tiene dos propiedades distintas: la de ser coloreada y la de ser roja.
</li>
            <li>  Ser rojo no es una propiedad independiente de ser coloreada.  El ser rojo hace parte constitutiva de la manera determinada de ser coloreado
</li>
            </ol>
</div>
    </section>
    
    <section  data-background-image ="img/redball.jpg" data-background-size = "contain" data-background-position="right">
        <div class="highlightred">        No es que esta bola tenga un color y adicionalmente tengan una propiedad en la que consiste su ser de color rojo. Más bien, decir que un objeto es rojo es decir que su manera de ser coloreado es, al menos parcialmente, roja: su ser rojo hace parte constitutiva de su manera determinada de ser coloreado. 
</div>
    </section>
    
    <section>No es mi intención defender una lectura de Aristóteles o defender una posición metafísica específica sobre la naturaleza de los colores. Más bien quiero utilizar estos ejemplos para mostrar cómo es podemos hablar de concepciones aditivas y concepciones transformativas.</section>
    
    <section>De acuerdo con una concepción aditiva del x de Y, una competencia, propiedad o aspecto x de Y es tal que la naturaleza de Y es independiente de x y x agrega algo a Y. Sostener una concepción aditiva del x de Y implica que es posible ofrecer una caracterización filosófica completa de Y sin apelar a su ser x –pues x es algo más, con una existencia independiente.</section>
    
    <section>En cambio, de acuerdo con una concepción transformativa del x de Y, una competencia, propiedad o aspecto x transforma Y tal que la naturaleza de Y no es independiente de su ser x.  Sostener una concepción transformativa de la x de Y implica defender que no es posible ofrecer una caracterización filosófica completa de Y sin apelar a su ser x –pues x constituye la menos parcialmente la naturaleza misma de Y. </section>
    
    <section>
        Ejemplos:
        <ol >
        <li>    Una concepción aditiva de la racionalidad humana afirma que nuestra racionalidad agrega algo a nuestra animalidad de manera en que podemos caracterizar nuestra racionalidad de manera independiente de nuestra animalidad.
</li>
        <li> Una concepción aditiva del rojo de una bola afirma que el ser rojo de la bola coloreada agrega algo a su ser coloreado de manera en que podemos caracterizar su ser rojo de manera independiente de su ser coloreado. </li>

        </ol>
    </section>
    
    <section>De acuerdo con una concepción aditiva de X en Y podemos entender X y Y de manera independiente. </section>
        <section>De acuerdo con una concepción transformativa de X en Y NO podemos entender X y Y de manera independiente, pues uno transforma al otro. </section>

    <section>
        <h1>¿Y la IA?</h1>
        <p class="fragment">Armados ahora con una descripción general de una concepción transformativa y una aditiva veamos cómo se formularía eso en el caso de la ética para la inteligencia artificial.</p> </section>
    
    <section>Según lo dicho, una concepción aditiva de la ética para la inteligencia artificial afirma que es posible ofrecer una caracterización filosófica de la inteligencia artificial sin necesidad de incluir competencias éticas. <p class="fragment"> En términos de una tarea específica, la concepción aditiva de la ética consiste en sostener que la tarea se puede llevar a cabo en su totalidad y que las consideraciones éticas son adicionales a las consideraciones sobre la tarea específica. La competencia ética es una más que tiene el programa. </p></section>
    
    <section>Si tenemos un algoritmo de categorización de una cara humana para determinar si se trata de alguien con rasgos caucásicos, entonces, en una concepción aditiva, las consideraciones éticas no afectan para nada la naturaleza de la tarea y bien pueden hacerse independientemente de las consideraciones que sí tienen que ver con la tarea. </section>
    
    <section>Las consideraciones éticas vienen antes o después de la tarea, o incluso en paralelo, pero de manera en que no afecten para nada la naturaleza misma del proceso de categorización. En una concepción aditiva, la competencia ética regula el comportamiento, pero no lo constituye.</section>
    
    
<section>En una concepción transformativa, las consideraciones éticas son ya parte del comportamiento y no es posible hacerlas independientemente de las demás consideraciones necesarias para el comportamiento. La ética pues determina la naturaleza misma del comportamiento. </section>
    
    <section>En términos de una tarea específica, la concepción transformativa de la ética consiste en sostener que la tarea sólo se puede llevar a cabo en su totalidad en la medida en que involucra esencialmente consideraciones éticas. Las consideraciones éticas no son adicionales a las consideraciones sobre la tarea específica. </section>
    
    
    <section>¿Qué implica decir que las consideraciones éticas son constitutivas de la manera de realizar una tarea? </section>
    
    <section>Saquen su cuaderno de lógica, por favor.</section>
    
    
    <section>
        <p  style="text-align:left;" class="doscuadros">
    1. p &#8594; q <br>
    2. &not; p    &#8594; q <br>
            --- <br>
       3. q
        </p>
        
        <div class="doscuadros "><p class="fragment">¿Qué hacer para rechazar este argumento?</p><p class="fragment">Uno puede demostrar la negación de la premisa 1 o 2.</p><p class="fragment">Uno puede también rechazar un argumento con esta misma estructura rechazando los principios lógicos sobre los que se basa.  (En este caso puede rechazar el principio del tercero excluido y adoptar una lógica trivalente, por ejemplo.)</p></div>
    </section>
    
    
    <section>
        <p>        Para rechazar el argumento
</p>
        
        <ol>
        
        <li class="">Demostrar algo más dentro de ese mismo sistema lógico.</li>
                    <li class="">Cambiar la forma de demostrar; cambiar el sistema lógico.</li>

        </ol>
    
    
    </section>
    
    <section>
        <p class="doscuadros">        El ejemplo de la lógica nos sirve para avanzar el entendimiento de la diferencia entre concepciones aditivas y transformativas de la ética: 
</p>
        
        <p class="doscuadros">        
            Una concepción transformativa de la ética en la IA implica una forma fundamentalmente diferente de entender su naturaleza, así como un cambio de lógica implica una forma fundamentalmente diferente de entender la naturaleza de la demostración. No se trata de decir algo más; es una cuestión de cambio de raiz.</p> </section>
    
    <section>El ejemplo de la lógica nos sirve además para ver que, aunque las dos concepciones sean fundamentalmente diferentes, eso no quiere decir que no haya nada en común. Dos lógicas diferentes pueden tener formas de argumentación en común. Sí implica que algunos de los aspectos de cada lógica serán diferentes y esa diferencia será esencial a la caracterización de la lógica. </section>
    
    <section>Este punto se puede aclarar volviendo al ejemplo del color de un objeto. 
No es que los objetos sean coloreados y adicionalmente tengan una propiedad en la que consiste su ser rojo; ser rojo y ser azul son maneras fundamentalmente diferentes de lo coloreado. Pero eso no implica que un objeto de color azul y un objeto de color rojo no tengan ninguna propiedad en común. Lo que implica es que en tanto su color, estos objetos son diferentes y esa diferencia será esencial. (Aunque se puede pensar que los objetos rojos y los objetos azules sí comparten algo en tanto su color en la medida en que ambos hacen parte del espectro electromagnético visible, en contra de esto hay toda una industria en la filosofía de la percepción que ha enfatizado la diferencia una descripción física de un color en términos de una longitud de onda y una descripción de un color como “rojo”. Cf. Jackson y la habitación de Mary.) 
</section>
    <section>Así, aunque una concepción transformativa de la ética implica que metafísicamente hay una diferencia entre un programa que realiza consideraciones éticas y un programa que no, eso no quiere decir que no haya nada en común entre esas formas de IA. Sólo implica que en lo que respecta a un nivel ético de caracterización, serán fundamentalmente diferentes. </section>
    
<section>Nada de lo dicho representa un argumento en favor de una concepción transformadora de la IA. Tampoco uno en contra de la concepción aditiva. Todo lo que he hecho hasta el momento ha sido procurar aclarar el sentido en que puede haber una diferencia en las concepciones y qué es lo que implica. En la próxima sección propongo una primera razón para adoptar una concepción transformativa de la ética en la IA.</section>    
<section  data-background-color="white" data-background-image ="img/ggm.png" data-background-size = "contain" data-background-position="right">

<div class="container">
<div class="row">

<div class="col-md-7"> 
 
<h3 style="text-align:left; background-color:white; color:#022461; ">Sesgos algorítmicos y la razón de la dificultad para encontrarlos</h3>
    </div>
      
</div>
</div>	
</section>     
    
    
<section>Volvamos a los sesgos</section>    
    
    
<section>De acuerdo con una concepción aditiva, un programa tendrá sesgos cuando no cuente con una capacidad adicional de eliminar, inhibir o favorecer las conductas apropiadas. Así, un sesgo en contra de rasgos de un adulto mayor y en favor de rasgos de un joven es el resultado de que el programa no cuente con una regulación adicional de sus salidas. Quizá falta una categorización, haya una mala recopilación de los datos, o la representación estadística no sea representativa. </section>    
    
    <section>De acuerdo con esta concepción, los sesgos se predican principalmente de una conducta específica: aquella a la que le faltó la regulación. Y los principales mecanismos para reducir o eliminar esos sesgos, entonces, serían maneras en que se le adiciona a este programa una capacidad para eliminar, inhibir o favorecer ciertas conductas.</section>
    
    
<section>Así, según una concepción aditiva de la ética, podríamos decir las medidas adoptadas hasta el momento han sido infructuosas porque falta dar todavía con el ingrediente secreto, una modificación más del algoritmo o una adición a las bases de datos. El problema más profundo es que por mucho que logremos en estos campos, sólo solucionará algunas de las formas de estar sesgados, de manera en que siempre estará sujeto a que funcione “bien” reflejando una sociedad que está mal. Se sigue estando sujeto a los sesgos más robustos de la sociedad –quizá justo aquellos que son más perniciosos. </section>    
    
<section>En cambio, de acuerdo con una concepción transformativa, no hay una sola manera en que un programa tiene sesgos. Todos los programas justos se parecerán unos a otros pero cada programa sesgado estará sesgado a su manera y no habrá una forma común de serlo.</section>    
    
<section> Así, los sesgos son definidos negativamente: un programa tiene un sesgo cuando no realiza las consideraciones éticas apropiadas. Y esto puede ser porque no realiza ninguna operación ética o porque la forma en que se realizan las operaciones no toma en cuenta la dignidad de las personas, o distingue con base en la condición o ... . Pero en todo caso no hay una sola cosa qué extirpar, no hay una parte que cambiar, no hay un solo error qué borrar. </section>    
    
<section> Un sesgo en contra de rasgos de adulto mayor y en favor de los rasgos de un joven no se entiende como el resultado de un aspecto específico del programa sino de la construcción total de la manera en que se toman decisiones.</section>    
    
<section> De acuerdo con esta concepción, los sesgos no se predican principalmente de una conducta específica sino de la totalidad del programa. Y los principales mecanismos para la eliminación o reducción del sesgo tendrán que estar al nivel de la modificación del programa como un todo y no la adición de un mecanismo regulador específico.</section>
    
    <section>Si adoptamos una concepción transformativa, no buscamos que al final de la fiesta la ética aparezca a limpiar el piso. No se espera que la respuesta llegue después de que se tomó la decisión sesgada para ofrecer un ingrediente secreto, una modificación más del algoritmo o una adición a las bases de datos. La respuesta, de acuerdo con esta concepción, implica la presencia de la ética en la definición misma del proceso para la toma de decisiones</section>
    
<section>La concepción transformativa nos ayuda a darle a sentido al actual estado de la situación.
    
    <br> Los problemas éticos de la IA son múltiples y no han podido ser identificados porque no se ha adoptado esta concepción.
    </section>   
    
    <section>Para terminar, quisiera resaltar cómo esto nos dice algo importantes sobre el estado de la IA. </section>   
    
    <section>Se suele señalar las maneras en que la IA artificial todavía no se parece a nosotros en la medida en que no hay aún pensamiento propiamente, no tiene genuina creatividad artística o no tiene la capacidad de emociones. No tenemos una persona artificial.</section>   
    
    <section>Pero eso hace de lado las maneras en que sí se parecen a nosotros: se pareen en la manera en que tenemos vicios. La IA incorpora nuestras fallas éticas y la copia y amplifica. </section>   
    
    <section> Pero así mismo señala la manera en que podemos mejorarla IA: la IA artificial será menos sesgada en el momento en que veamos el problema más como una instancia del problema humano de cómo vivir una buena vida y menos como una indagación por el ingrediente secreto. Menos como una cuestión extra y más como una cuestión fundamental.</section>
    
    


<section  data-background-color="white" data-background-image ="img/ggm.png" data-background-size = "contain" data-background-position="right">

<div class="container">
<div class="row">

<div class="col-md-3"> 
    <h1><br></h1>

<h2 style="text-align:left; background-color:white; color:#022461; ">Gracias.</h2>
    
    <div class="col-md-6"> z
        <p style="text-align:left; background-color:white; color:#022461;"> <font size="5">Juan Camilo Espejo-Serna</font> <br> <font size="4">Universidad de la Sabana<br>juan.espejo1@unisabana.edu.co</font>
        <br><br></p></div>
<!--    <div style="text-align:left; background-color:white; color:#022461;"><a style="color:#022461; text-decoration: underline;" href="../jcunisabana.github.io/">Juan Camilo Espejo Serna</a>-->

<!--
<font size="5"><span style="text-align:left; background-color:white; color:#022461; font-family:'Lucida Console', monospace"><smal>juan.espejo1@unisabana.edu.co</smal></span>
</font> 
-->
    </div>
      
</div>
   

</div>	

</section>
			</div>
		</div>
<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>
<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});


		</script>

	</body>
</html>
